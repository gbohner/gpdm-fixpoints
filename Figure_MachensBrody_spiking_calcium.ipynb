{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "\n",
    "# Import main functionality\n",
    "#from GPDM_direct_fixedpoints import *\n",
    "from thesis_Experiment_2d_MachensBrody import *\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "#Â Saving outputs and timing\n",
    "import pickle, datetime, time\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing packages\n",
    "# import sys\n",
    "# # !conda install --yes --prefix {sys.prefix} <PKGNAME>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(fname, arr):\n",
    "    f_handle = open(\"Figures/CSV/\"+fname, 'wb')\n",
    "    np.savetxt(f_handle, arr, delimiter=\",\")\n",
    "    f_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loading_uneven = scipy.io.loadmat('thesis_Machens_Brody_sim/thesis_MachensBrodySim_20181230T121236_loading_uneven.mat', squeeze_me=True)\n",
    "data_loading_even = scipy.io.loadmat('thesis_Machens_Brody_sim/thesis_MachensBrodySim_20181230T121236_loading_even.mat', squeeze_me=True)\n",
    "data_decision = scipy.io.loadmat('thesis_Machens_Brody_sim/thesis_MachensBrodySim_20181230T121236_decision.mat', squeeze_me=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP_fit_saves = [\n",
    "    pickle.load(open('Experiment_machens_results/' + save_fname, 'rb')) for save_fname in [\n",
    "        'machens_decision_20190421T040311.pkl',\n",
    "        'machens_loading_even_20190421T171829.pkl',\n",
    "        'machens_loading_uneven_20190421T053043.pkl',\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the nullclines (originally defined in the space of electric conductances), \n",
    "# such that they follow the transformed data after adding spiking and calcium imaging\n",
    "\n",
    "scalings = list()\n",
    "for dataset_name in ['data_loading_even', 'data_decision', 'data_loading_uneven']:\n",
    "    if dataset_name=='data_decision':\n",
    "        cur_data=data_decision\n",
    "        cur_simParams = GP_fit_saves[0][3]\n",
    "    if dataset_name=='data_loading_even':\n",
    "        cur_data=data_loading_even\n",
    "        cur_simParams = GP_fit_saves[1][3]\n",
    "    if dataset_name=='data_loading_uneven':\n",
    "        cur_data=data_loading_uneven\n",
    "        cur_simParams = GP_fit_saves[2][3]\n",
    "\n",
    "    # Then take into account calcium dynamics and binning for the true nullcline \n",
    "\n",
    "    # Get the calcium convultion kernel\n",
    "    conv_t, conv_weights = fred_curve(cur_simParams['fred_params'])\n",
    "\n",
    "    # Get average contribution to deltaF/F relative fluoresecence increase per spike per frame\n",
    "    # (essentially I pick points randomly on the convolution curve per frame - due to instantaneous sampling via Ca imaging)\n",
    "    # , and want to know the expected value of % fluorescence increase per frame, given a single uniformly distributed spike)\n",
    "    total_frames = np.floor(cur_simParams['T_max'] / cur_simParams['delta_t'])\n",
    "    fluorescence_per_spike_per_frame_total = np.mean(conv_weights) * total_frames\n",
    "    # However, as trials are finite length in time, only a spike at t=0 will contribute this much on average.\n",
    "    # In fact if we assume here that a spike is uniformly distributed in time, it will contribute half of this on average\n",
    "    fluorescence_per_spike_per_frame_cutoff = fluorescence_per_spike_per_frame_total / 2\n",
    "\n",
    "\n",
    "    # And now scale the nullclines appropriately, taking into account the baseline fluorescence level\n",
    "    # First turn the firing rates from Hz (spikes per sec) to spikes per frame\n",
    "    # Then multiply by per spike per frame fluorescence, and finally multiply the baseline brightness by this fractional change\n",
    "    frames_per_sec = 1000/cur_simParams['delta_t']\n",
    "    cur_data['nullcline1_calc'] = ((\n",
    "            cur_data['nullcline1_fr']/frames_per_sec*fluorescence_per_spike_per_frame_cutoff\n",
    "        ) + 1)*cur_simParams['baseline_brightness']\n",
    "    cur_data['nullcline2_calc'] = ((\n",
    "            cur_data['nullcline2_fr']/frames_per_sec*fluorescence_per_spike_per_frame_cutoff\n",
    "        ) + 1)*cur_simParams['baseline_brightness']\n",
    "    #scalings.append(fluorescence_per_neuron_per_frame_given_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt([\n",
    "#      plt_type.Scatter(x = cur_data['data']['tt'][0], y = cur_data['data']['xx'][0]),\n",
    "#     plt_type.Scatter(x = cur_data['data']['rt'][0], y = cur_data['data']['gsy'][0]),\n",
    "#     plt_type.Scatter(x = cur_data['data']['rt'][0], y = cur_data['data']['gsx'][0])\n",
    "# ])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory\n",
    "\n",
    "def machens_callback_plot_external(pvec_partial, \n",
    "                                  opt_params, init_paramvec, transforms, dict_ind, dict_shape, nullclines=None, \n",
    "                                   fp_size=None, fp_color=None\n",
    "                                 ):\n",
    "    \n",
    "    paramvec = replace_params(pvec_partial, opt_params, init_paramvec)\n",
    "    paramdict = vec_to_params(paramvec, dict_ind, dict_shape, transforms)\n",
    "\n",
    "    # Unpack the usual parameters\n",
    "    (Sigma_eps, mu_0_0, Sigma_0_0, C, Sigma_nu, z, u, Sigma_u, lengthscales, kernel_variance, s, J, Sigma_s)  = \\\n",
    "        paramdict.values()\n",
    "\n",
    "    # Plot transition function\n",
    "#     xtmp, ytmp = np.meshgrid(np.linspace(np.min(z[0,:]),np.max(z[0,:]),16),\n",
    "#                              np.linspace(np.min(z[1,:]),np.max(z[1,:]),16))\n",
    "    xtmp, ytmp = np.meshgrid(np.linspace(0.8,3.0,16),\n",
    "                         np.linspace(0.8,3.0,16))\n",
    "    xstar = np.concatenate([xtmp.flatten()[:,None], ytmp.flatten()[:,None]], axis=1).T\n",
    "\n",
    "    L, targets, params = fp_get_static_K(eta=kernel_variance, lengthscales=lengthscales, z=z, u=u, s=s, J=J, \n",
    "                                         sig_eps=Sigma_eps, sig_u=Sigma_u, sig_s=Sigma_s, sig_J = None)\n",
    "    mu_star, sig_star, K_pred = fp_predict(xstar, L, targets, params)\n",
    "\n",
    "    #print(time_full_iter(pvec, y, D, Nz, Ns)[0])\n",
    "    \n",
    "    quiver_fig = plotly.figure_factory.create_quiver(np.squeeze(xstar[0,:]), \n",
    "                                                     np.squeeze(xstar[1,:]), \n",
    "                                                     np.squeeze(mu_star[0,:]-xstar[0,:]), \n",
    "                                                     np.squeeze(mu_star[1,:]-xstar[1,:]),\n",
    "                                                    scale=.25,\n",
    "                                                    arrow_scale=.4,)\n",
    "\n",
    "#     quiver_fig = plotly.figure_factory.create_quiver(np.squeeze(y_t1_rsh[0,:]), \n",
    "#                                                  np.squeeze(y_t1_rsh[1,:]), \n",
    "#                                                  np.squeeze(y_t_rsh[0,:]-y_t1_rsh[0,:]), \n",
    "#                                                  np.squeeze(y_t_rsh[1,:]-y_t1_rsh[1,:]),\n",
    "#                                                 scale=.25,\n",
    "#                                                 arrow_scale=.4,)\n",
    "    \n",
    "    # Add points to figure\n",
    "    \n",
    "    # Map Sigma_s values to the range 12-22\n",
    "    if fp_size is None:\n",
    "        if Sigma_s.size>1:\n",
    "            FP_SIZE = -np.squeeze(np.log(Sigma_s))\n",
    "            FP_SIZE = FP_SIZE - np.min(FP_SIZE)\n",
    "            FP_SIZE = (FP_SIZE/np.max(FP_SIZE))*10. + 12.\n",
    "        else:\n",
    "            FP_SIZE = 12.\n",
    "    else:\n",
    "        FP_SIZE=fp_size\n",
    "        \n",
    "    if fp_color is None:\n",
    "        fp_color = 'green'\n",
    "    \n",
    "#     # Inducing point locations\n",
    "#     quiver_fig['data'].append(\n",
    "#         plt_type.Scatter(x=np.atleast_1d(np.squeeze(z[0,:])), y=np.atleast_1d(np.squeeze(z[1,:])), \n",
    "#                          mode='markers', name=\"Inducing loc\", marker=dict(size=10)))\n",
    "    \n",
    "    # Estimated fixed points\n",
    "    quiver_fig['data'].append(\n",
    "        plt_type.Scatter(x=np.atleast_1d(np.squeeze(s[0,:])), y=np.atleast_1d(np.squeeze(s[1,:])), \n",
    "                         mode='markers', name=\"Fixed loc\", marker=dict(size=FP_SIZE, color=fp_color)))\n",
    "        \n",
    "    # Add nullclines    \n",
    "    if nullclines is not None:\n",
    "        quiver_fig['data'].append(plt_type.Scatter(x=nullclines['nullcline1_calc'][0,:], y=nullclines['nullcline1_calc'][1,:]))\n",
    "        quiver_fig['data'].append(plt_type.Scatter(x=nullclines['nullcline2_calc'][0,:], y=nullclines['nullcline2_calc'][1,:]))\n",
    "\n",
    "#         quiver_fig['data'].append(plt_type.Scatter(x=nullclines['nullcline1'][0,:], y=nullclines['nullcline1'][1,:]))\n",
    "#         quiver_fig['data'].append(plt_type.Scatter(x=nullclines['nullcline2'][0,:], y=nullclines['nullcline2'][1,:]))\n",
    "        \n",
    "    \n",
    "    # Add layout\n",
    "    quiver_fig['layout'] = plt_type.Layout(xaxis={'range': [-1.,8.]}, yaxis={'range': [-1.,8.]})\n",
    "    \n",
    "    \n",
    "    plt(quiver_fig)\n",
    "    \n",
    "    return [xstar.T, (mu_star-xstar).T, #Quiver plot\n",
    "            nullclines['nullcline1_calc'].T, #Nullcline 1\n",
    "            nullclines['nullcline2_calc'].T, #Nullcline 2\n",
    "            s.T, FP_SIZE[:,None], fp_color] # Fixed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSingle(curFit, curData=None):\n",
    "    [y_train, x_train,\n",
    "     all_results, simParams,\n",
    "     init_paramvec, dict_ind, dict_shape, opt_params, \n",
    "     bnds, transforms] = curFit\n",
    "    \n",
    "    paramvec = replace_params(all_results[-1].x, opt_params, init_paramvec)\n",
    "    paramdict = vec_to_params(paramvec, dict_ind, dict_shape, transforms)\n",
    "\n",
    "    # Unpack the usual parameters\n",
    "    (Sigma_eps, mu_0_0, Sigma_0_0, C, Sigma_nu, z, u, Sigma_u, lengthscales, kernel_variance, s, J, Sigma_s)  = \\\n",
    "        paramdict.values()\n",
    "\n",
    "    cur_eigs=np.zeros((paramdict['J'].shape[0],2))\n",
    "    \n",
    "    color_arr = np.array(['red', 'blue', 'black'])\n",
    "    color_choice = np.squeeze(np.int32(np.empty(paramdict['Sigma_s'].shape)))\n",
    "    for i in range(paramdict['J'].shape[0]):\n",
    "        cur_eigs[i,:] = np.sort(np.linalg.eig(paramdict['J'][i,:,:])[0])\n",
    "        color_choice[i] = np.int32(cur_eigs[i,1]>1)\n",
    "    #color_choice[np.squeeze(paramdict['Sigma_s'] > fp_dynamic_threshold(curFit))] = 2\n",
    "    \n",
    "        \n",
    "    quiver_fig = machens_callback_plot_external(all_results[-1].x, \n",
    "                          opt_params, init_paramvec, transforms, dict_ind, dict_shape,\n",
    "                                   nullclines=curData, fp_color = color_arr[color_choice]\n",
    "                         )\n",
    "    \n",
    "    return [quiver_fig, cur_eigs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = plotSingle(GP_fit_saves[0], data_decision)\n",
    "tmp = plotSingle(GP_fit_saves[1], data_loading_even)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure simulation details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raster plot for trial #0 in the decision dataset\n",
    "import matplotlib.pyplot as matplt\n",
    "#import seaborn as sns\n",
    "\n",
    "n_trial = 0\n",
    "cur_spiketimes = np.concatenate([\n",
    "    data_decision['data']['spikesx'][n_trial],\n",
    "    data_decision['data']['spikesy'][n_trial]],\n",
    "    axis = 0)\n",
    "\n",
    "def plotRaster(spiketimes, **kwargs):\n",
    "    \"\"\" function to plot raster plot for a given trial\"\"\"\n",
    "    ax = matplt.gca()\n",
    "    for neur in range(spiketimes.shape[0]):\n",
    "        for spike in range(spiketimes.shape[1]):\n",
    "            if spiketimes[neur,spike]>0:\n",
    "                matplt.vlines(spiketimes[neur,spike]/1000, neur + .5, neur + 1.5, **kwargs)\n",
    "    \n",
    "    matplt.ylim(.5, spiketimes.shape[0] + .5)\n",
    "    return ax\n",
    "\n",
    "matf = matplt.figure(figsize=(6,4))\n",
    "\n",
    "plotRaster(cur_spiketimes)\n",
    "#sns.despine()\n",
    "# Same as despine:\n",
    "for d in [\"left\", \"top\", \"bottom\", \"right\"]:\n",
    "    matplt.gca().spines[d].set_visible(False)\n",
    "matplt.xticks([0,1,2])\n",
    "#matplt.xlabel('t (sec)')\n",
    "#matplt.ylabel('neuron number')\n",
    "matplt.show()\n",
    "matf.savefig(\"Figures/raster_decision.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The FRED curve as inset on calcium simulation\n",
    "simParams = GP_fit_saves[0][3]\n",
    "tmp = fred_curve(simParams['fred_params'])\n",
    "plt([plt_type.Scatter(x=tmp[0], y=tmp[1])])\n",
    "save_csv(\"figure_4_5_fred_inset.csv\",  np.stack(tmp).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example convolution (noiseless data)\n",
    "# Create data with no noise to show examples\n",
    "visParams = copy.deepcopy(simParams)\n",
    "visParams['delta_t'] = 1\n",
    "visParams['Sigma_calc_obs'] = 0\n",
    "y_noiseless = createData(data_decision, visParams, batchnum=0)\n",
    "\n",
    "# Show also the subsampled data used for fitting\n",
    "y_noisy = GP_fit_saves[0][0]\n",
    "y_noisy_obs_times = data_decision['data']['rt'][0][range(0, min(simParams['T_max'], data_decision['data']['rt'][0].shape[0]), simParams['delta_t'])]\n",
    "\n",
    "# An example + and - neuron vs time on one trial \n",
    "all_plots = []\n",
    "\n",
    "n_trial=0\n",
    "\n",
    "all_plots.append(plt_type.Scatter(x=np.arange(y_noiseless.shape[1]), y = y_noiseless[:1, :, n_trial].mean(0)))\n",
    "all_plots.append(plt_type.Scatter(x=np.arange(y_noiseless.shape[1]), y = y_noiseless[41:42, :, n_trial].mean(0)))\n",
    "all_plots.append(plt_type.Scatter(x=y_noisy_obs_times, y = y_noisy[:1, :, n_trial].mean(0), mode='markers'))\n",
    "all_plots.append(plt_type.Scatter(x=y_noisy_obs_times, y = y_noisy[41:42, :, n_trial].mean(0), mode='markers'))\n",
    "    #all_plots.append(plt_type.Scatter(x=y[:30,:, n_trial].mean(0), y=y[-30:,:, n_trial].mean(0)))\n",
    "    \n",
    "plt(all_plots)\n",
    "\n",
    "save_csv(\"figure_4_5_calc_nonoise0.csv\", \n",
    "         np.stack([np.arange(y_noiseless.shape[1]), y_noiseless[:1, :, n_trial].mean(0)], axis=1))\n",
    "save_csv(\"figure_4_5_calc_nonoise1.csv\", \n",
    "         np.stack([np.arange(y_noiseless.shape[1]), y_noiseless[41:42:, :, n_trial].mean(0)], axis=1))\n",
    "save_csv(\"figure_4_5_calc_sample0.csv\", \n",
    "         np.stack([y_noisy_obs_times, y_noisy[:1, :, n_trial].mean(0)], axis=1))\n",
    "save_csv(\"figure_4_5_calc_sample1.csv\", \n",
    "         np.stack([y_noisy_obs_times, y_noisy[41:42, :, n_trial].mean(0)], axis=1))\n",
    "\n",
    "#save_csv((\"figure3_panel1_line2_ind%0.2d\" % (i)) + \".csv\", a[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure GP fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision making fit\n",
    "i = 0\n",
    "[a, cur_eigs] = plotSingle(GP_fit_saves[i], data_decision)\n",
    "\n",
    "# Line1 - Quiver plot (simply coordinates, do styling in latex)\n",
    "save_csv((\"figure_4_5_gpfit_line1_ind%0.2d\" % (i)) + \".csv\", np.concatenate([a[0], a[1]],axis=1))\n",
    "\n",
    "# Line2 - Nullcline1\n",
    "save_csv((\"figure_4_5_gpfit_line2_ind%0.2d\" % (i)) + \".csv\", a[2])\n",
    "\n",
    "# Line3 - Nullcline2\n",
    "save_csv((\"figure_4_5_gpfit_line3_ind%0.2d\" % (i)) + \".csv\", a[3])\n",
    "\n",
    "# Line4 - Fixed point coordinates, sizes as 3rd column and (color as 4th column) # Python plot marker size: a[-2].marker.size[:,None]\n",
    "save_csv((\"figure_4_5_gpfit_line4_ind%0.2d\" % (i)) + \".csv\", np.concatenate([a[4], a[5], cur_eigs],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading fit\n",
    "i = 1\n",
    "[a, cur_eigs] = plotSingle(GP_fit_saves[i], data_loading_even)\n",
    "\n",
    "# Line1 - Quiver plot (simply coordinates, do styling in latex)\n",
    "save_csv((\"figure_4_5_gpfit_line1_ind%0.2d\" % (i)) + \".csv\", np.concatenate([a[0], a[1]],axis=1))\n",
    "\n",
    "# Line2 - Nullcline1\n",
    "save_csv((\"figure_4_5_gpfit_line2_ind%0.2d\" % (i)) + \".csv\", a[2])\n",
    "\n",
    "# Line3 - Nullcline2\n",
    "save_csv((\"figure_4_5_gpfit_line3_ind%0.2d\" % (i)) + \".csv\", a[3])\n",
    "\n",
    "# Line4 - Fixed point coordinates, sizes as 3rd column and (color as 4th column) # Python plot marker size: a[-2].marker.size[:,None]\n",
    "save_csv((\"figure_4_5_gpfit_line4_ind%0.2d\" % (i)) + \".csv\", np.concatenate([a[4], a[5], cur_eigs],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1]:\n",
    "    [a, cur_eigs] = plotSingle(GP_fit_saves[i], data_excitation[i])\n",
    "\n",
    "    # We need the traces for training data, GP variances and fixed points\n",
    "\n",
    "    # Line1 - Quiver plot (simply coordinates, do styling in latex)\n",
    "    save_csv((\"figure3_panel1_line1_ind%0.2d\" % (i)) + \".csv\", np.concatenate([a[0], a[1]],axis=1))\n",
    "\n",
    "    # Line2 - Nullcline1\n",
    "    save_csv((\"figure3_panel1_line2_ind%0.2d\" % (i)) + \".csv\", a[2])\n",
    "\n",
    "    # Line3 - Nullcline2\n",
    "    save_csv((\"figure3_panel1_line3_ind%0.2d\" % (i)) + \".csv\", a[3])\n",
    "\n",
    "    # Line4 - Fixed point coordinates, sizes as 3rd column and (color as 4th column) # Python plot marker size: a[-2].marker.size[:,None]\n",
    "    save_csv((\"figure3_panel1_line4_ind%0.2d\" % (i)) + \".csv\", np.concatenate([a[4], a[5], cur_eigs],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3B - Eigenvalues of middle point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excitation_values_true = 1.5 + 0.01*np.array(excitation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eigvals = np.zeros((0,2))\n",
    "mean_evecs = np.zeros((2,2))\n",
    "\n",
    "for i in range(len(GP_fit_saves)):\n",
    "    \n",
    "    [y_train, x_train,\n",
    "     all_results, simParams,\n",
    "     init_paramvec, dict_ind, dict_shape, opt_params, \n",
    "     bnds, transforms] = GP_fit_saves[i]\n",
    "\n",
    "    paramvec = replace_params(all_results[-1].x, opt_params, init_paramvec)\n",
    "    paramdict = vec_to_params(paramvec, dict_ind, dict_shape, transforms)\n",
    "\n",
    "    # Unpack the usual parameters\n",
    "    (Sigma_eps, mu_0_0, Sigma_0_0, C, Sigma_nu, z, u, Sigma_u, lengthscales, kernel_variance, s, J)  = \\\n",
    "        paramdict.values()[:12]\n",
    "\n",
    "    if np.any(np.isnan(lengthscales)):\n",
    "        set_trace()\n",
    "\n",
    "    # Deal with the extra possible parameters\n",
    "    Sigma_s = None; Sigma_J=None;\n",
    "    if 'Sigma_s' in paramdict.keys():\n",
    "        Sigma_s = paramdict['Sigma_s']\n",
    "    if 'Sigma_J' in paramdict.keys():\n",
    "        Sigma_J = paramdict['Sigma_J']\n",
    "\n",
    "    # Get the middle fixed point in every case\n",
    "    mid_ind = np.argsort((s[0,:]-s[1,:])**2)[0]\n",
    "    \n",
    "    #print s[:,mid_ind], mid_ind\n",
    "    \n",
    "    [evs, evecs] = np.linalg.eig(paramdict['J'][mid_ind,:,:])\n",
    "    ev_inds = np.argsort(evs)\n",
    "    \n",
    "    all_eigvals = np.concatenate([all_eigvals, evs[ev_inds,None].T], axis=0)\n",
    "    mean_evecs = mean_evecs + evecs[:,ev_inds]\n",
    "    \n",
    "mean_evecs = mean_evecs / (1.0*len(GP_fit_saves))\n",
    "\n",
    "# Line1 and 2 - Eigenvalues of middle point vs excitation (simply coordinates, do styling in latex)\n",
    "save_csv(\"figure3_panel2_line1\" + \".csv\", np.concatenate([excitation_values_true[:,None], all_eigvals],axis=1))\n",
    "\n",
    "# Line 3 - Mean eigenvector directions\n",
    "save_csv(\"figure3_panel2_line2\" + \".csv\", np.concatenate([np.zeros((2,2)), mean_evecs.T],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_evecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line5 - Fixed point coordinates, sizes as 3rd column and (color as 4th column) # Python plot marker size: a[-2].marker.size[:,None]\n",
    "save_csv(\"figure2_panel3_line1.csv\", np.concatenate([all_r_vals, all_x_vals, all_sizes, all_color_inds],axis=1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
